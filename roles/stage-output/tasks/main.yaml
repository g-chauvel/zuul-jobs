- name: Register sources
  stat:
    path: "{{ zj_source.key }}"
  loop: "{{ zuul_copy_output|dict2items }}"
  loop_control:
    loop_var: zj_source
  register: sources
  no_log: true

- name: Build the extensions list from a dict (or empty)
  set_fact:
    extension_list: >
      {% set extensions = ['__do_not_match__'] -%}
      {% if extensions_to_txt -%}
        {% for extension, extension_bool in extensions_to_txt.items() -%}
          {% if extension_bool -%}
            {% set _ = extensions.append(extension) -%}
          {% endif -%}
        {% endfor -%}
      {% endif -%}
      {{- extensions -}}

- name: Build the extensions regular expression
  set_fact:
    extensions_regex: "^(.*)\\.({{ extension_list | join('|') }})$"

# TODO(andreaf) We might want to enforce that zj_source.value is a valid value
# in docs, artifacts, logs. Null case already handled.
# NOTE(andreaf) Files or folders that start with a '.' are renamed to starting
# with an '_' else they would not be visible in the logs folder once uploaded.
# Extension changes are handled later via find as we want to rename files
# included of folders specified in `zuul_copy_output` (except for logs_txt,
# which is handled here).
- name: Set source and destination for files and folders
  set_fact:
    source: "{{ zj_result.stat.path }}"
    dest: "{{ zj_result.zj_source.value.split('_')[0] }}/{{ zj_result.stat.path|basename|regex_replace('^(\\..*)$', '_\\1') }}{% if zj_result.zj_source.value.endswith('_txt') %}.txt{% endif %}"
    type: "{{ zj_result.zj_source.value.split('_')[0] }}"
  with_items: "{{ sources.results }}"
  loop_control:
    loop_var: zj_result
  when:
    - zj_result.stat.exists
    - zj_result.zj_source.value
  register: results
  no_log: true

- name: Build a list of source, dest dictionaries
  set_fact:
    all_sources: "{{ results.results | selectattr('ansible_facts', 'defined') | map(attribute='ansible_facts') | list }}"

- name: Ensure target folders exist
  become: true
  file:
    path: "{{ stage_dir }}/{{ zj_output_dirs }}"
    state: directory
    owner: "{{ ansible_user }}"
  with_items:
    - docs
    - artifacts
    - logs
  loop_control:
    loop_var: zj_output_dirs

- name: Copy files and folders to staging folder
  # remote_src copy does not work recursively, synchronise is restricted by
  # zuul, using command
  command: cp -pRL {{ zj_source.source }} {{ stage_dir }}/{{ zj_source.dest }}
  become: true
  with_items: "{{ all_sources }}"
  loop_control:
    loop_var: zj_source

- name: Make all log files readable
  file:
    state: directory
    dest: "{{ stage_dir }}/logs"
    mode: u=rwX,g=rX,o=rX
    recurse: yes
  become: yes

- name: Discover log files that match extension_list
  find:
    paths: "{{ stage_dir }}/logs"
    patterns: "{{ extensions_regex }}"
    use_regex: true
    recurse: true
    file_type: 'file'
  register: log_files_to_rename

- name: Rename log files that match extension_list
  shell: "mv {{ zj_log_file.path }} {{ zj_log_file.path | regex_replace(extensions_regex, '\\1_\\2.txt') }}"
  with_items: "{{ log_files_to_rename.files }}"
  loop_control:
    loop_var: zj_log_file
  args:
    chdir: "{{ stage_dir }}/logs"
  tags:
    - skip_ansible_lint

- block:
    - name: Discover log files for compression
      find:
        paths: "{{ stage_dir }}/logs"
        recurse: true
        file_type: 'file'
      register: log_files_to_compress

    # NOTE(andreaf) The ansible module does not support recursive archive, so
    # using gzip is the only option here. The good bit is that gzip itself is
    # almost idempotent, as it will not compress again files with .gz extension.
    # gzip will however return 1 if any compressed file is encountered, so we
    # must ignore that (there's no specific error code).
    - name: Archive everything from logs
      shell: gzip --recursive --best {{ zj_log_file.path }} || true
      args:
        chdir: "{{ stage_dir }}/logs"
      with_items: "{{ log_files_to_compress.files }}"
      loop_control:
        loop_var: zj_log_file
      tags:
        - skip_ansible_lint
  when:
    - stage_compress_logs
